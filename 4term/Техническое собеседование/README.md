# Тест-кейс
>Опишите возможную программную, аппаратную и сетевую архитектуру любого высоконагруженного web-сервиса. 

![alt text](https://github.com/mafin1799/BMSTU/blob/main/4term/Техническое%20собеседование/web1.jpg?raw=true)



1) В: Опишите возможную программную, аппаратную и сетевую архитектуру любого высоконагруженного web-сервиса.
О: В общем случае web-сервис состоит из:
1) Фронтенд сервера (само приложение)
2) Бекенд сервера (web-сервер)
3) БД
4) Файловый сервер (опционально)
Сервера как правило управляются ОС Linux.
Запрос от клиента проходит путь: сначала через DNS он направляется на фронтенд сервер. Если запрос был связан с файлом на файловом сервере, то фронтенд передаёт его последнему, получает ответ и возвращает пользователю по протоколу HTTP. Иначе запрос передаётся по FastCGI к веб-серверу, где находится код самого сервиса, исполняемый файлы, интерпретатор. Если запрос связан с данными из БД, то бекэнд сервер отправляет его к БД, где он исполняется, и результат передаёт обратно через фронт-сервер пользователю. Либо исполняет его на своей стороне, если это, например, выполнение функции сервиса, и также отправляет результат пользователю. 
Далее, с ростом нагрузки, сервера масштабируются. Сначала вертикально (улучшением существующего сервера), затем, когда дальнейшие улучшения одного нецелесообразны или невозможны, горизонтально (т.е. путём приобретения новых серверов).
При масштабировании до уровня high load происходит разбивка серверов на функциональные группы.
В зависимости от нагрузки, один фронтенд сервер реплицируется на кластер из нескольких серверов.
Один бекэнд сервер также реплицируется на кластер из нескольких серверов. Бекэнд сервера закрываются во внутренней подсети, чтобы не было возможности доступа к ним у посторонних лиц.
При необходимости хранения большого количество статических файлов, добавляется один или несколько файловых серверов.
Сервер с БД также масштабируется. Существует две стратегии - шардинг и репликация. 
Репликация - создание полного дубликата основной БД. Тогда появляется система master-slave. Master - основной сервер БД, где происходят изменения в данных (add, update, delete). Slave - вспомогательный сервер, копирующий данные с мастера. С него следует читать данные и таких серверов может быть несколько. Репликация применима, когда операция чтения данных из БД много больше операций изменения данных. 
Шардинг - разделение (партиционирование) БД на части так, чтобы каждую из них можно было вынести на отдельный сервер. Шардинг делится на горизонтальный и вертикальный.
Вертикальный - выделение таблицы или группы таблиц на отдельный сервер (например, таблицу с фотографиями на один сервер, с видео - на другой, с учётками - на третий и т.д.).
Горизонтальный - разделение одной таблицы на разные сервера. Необходимо использовать для огромных таблиц, которые не умещаются на одном сервере. Тогда:
1) На нескольких серверах создаются одинаковые по структуре пустые таблицы;
2) В приложении выбираются условия, по которому будут делиться данные;
3) Перед каждым обращением к таблице происходит выбор нужного соединения.
Таблицы следует масштабировать поэтапно, по мере их роста. 
Возможно совместное использование шардинга и репликации, что также приводит к обеспечению отказоустойчивости (при выходе из строя одного из серверов шарда, всегда будет запасной).
Важным вспомогательным элементом при масштабировании под высокие нагрузки является автоматизация кэширования и система асинхронных очередей. Кэширование производится на отдельных серверах. Кэшируются страницы по разным группам: 
простые; посещаемые; сложные, но важные; прочие полезные.
Сервер очередей обеспечивает уменьшение временных затрат на исполнение сложных частей кода, отправляя их на параллельное асинхронное исполнение другим специальным Worker-серверам. Так, сначала бекэнд посылает задачу системе очередей, которая только хранит этот список задач, включащих в себя информацию о том, что и как нужно выполнить. А затем она раздаёт эти задачи воркерам, где эти задачи исполняются по данным инструкциям. Результат возвращается бекэнд серверу. 
 
2) В: Какие технологии целесообразно использовать на серверной и клиентской частях проекта?
О: Клиент (сайт): фронтэнд сайта создаётся с использованием стандартной связки HTML + CSS + JS. Можно использовать фреймворки, как Bootstrap, для быстрой генерации фронтэнда, препроцессоры CSS и HTML для упрощения работы, фреймворки для JavaScript. 
Сервер: 
- В качестве ОС на всех серверах целесообразно использовать Linux, например, Ubuntu, т.к. Линукс легко администрируем, зачастую опен-сорс, более отказоустойчив. 
- В качестве веб-сервера для фронтенд- и бекэнд-серверов можно выбирать между Nginx и Apache. Но Nginx хорошо подходит для высоконагруженных сервисов, т.к. построен на асинхронной событийно управляемой архитектуре, что помогает обрабатывать большое количество сессий одновременно, не блокируя доступ к каналам ввода-вывода. При этом он легко масштабируем. Но Apache так же можно использовать, его сильная сторона - модульная архитектура. 
- В качестве СУБД подойдёт MySQL, т.к. она очень проста в использовании, масштабируема. 
- Бекэнд приложения можно реализовывать на интерпретируемых языках, как-то: PHP, Python + Django, Ruby on Rails, - но интерпретируемые языки сильно проигрывают в скорости компилируемым на больших нагрузках. В таком случае, самые нересурсоёмкие части кода можно реализовывать на скриптовых языках, остальную часть лучше реализовывать с использованием компилируемых языков, например, Java или Pure C. Таким образом, важно найти баланс между удобством написания кода и производительностью, не собирая при этом громоздкую кучу технологий. 
- Для файлового сервера достаточно лишь необходимых программ для хранения и передачи файлов. Обработка файлов производится на стороне клиента
 
3) В: Как бы вы организовали хранение данных пользователей, файлов?
О: Хранение данных пользователей и файлов при высоких нагрузках будет занимать большое количество дискового пространства, следовательно, следует грамотно масштабировать БД. Для этого существует две стратегии - шардинг и репликация. Для некоторых таблиц, например, пользовательских медиа-файлов (таблицы с фотографиями, таблицы с видеозаписями, таблицы с аудиозаписями) уместно одновременное использование обоих подходов. То есть, крупная таблица разбивается на несколько шардов, при этом каждый из шардов дополнительно горизонтально масштабируется. Важно иметь резервные копии каждой из таблиц. Также необходим сервер, хранящий локально только временные файлы, требующиеся на время выполнения запроса и удаляющиеся после завершения его выполнения.  
Если статических файлов в приложении достаточно много, целесообразно ввести один или кластер из нескольких файловых серверов под управлением ОС Linux и web-сервера nginx на выделенном субдомене для таких серверов. 
 
4) В: Какие способы оптимизации работы под нагрузкой можно применить и в каких случаях?
О: Оптимизировать можно все основные компоненты приложения. Есть несколько общих стратегий:
- Старые сервера обновлять на новые и, по возможности, более производительные. 
- Проверить код на наличие алгоритмов, хорошо работавших на меньших количествах запросов, но переставших отвечать требованиям с увеличением нагрузки. 
- Также, если основная часть кода реализована на скриптовых языках, можно переписать часть ресурсоёмкого кода на Си или Джава.
- Распараллелить крупный алгоритм на несколько серверов.
Далее, важным инструментом является кэширование. Nginx позволяет кэшировать код. Какой-либо кусок кода с выборкой данных, сложных запросах к API, например, скрипт, генерирующий страницу с фидлентой, его результат можно сохранить в память, откуда будет выдаваться пользователю. При этом раз в t секунд старая страница будет удаляться из памяти, а новая генерироваться и сохраняться снова. Можно кэшировать fastcgi.
Полезным является использование систем очередей. 
Затем остаётся только горизонтальное масштабирование компонентов. Для начала стоит выяснить, какая часть приложения является узким местом. 
- Чаще всего таким узким местом является БД. Для начала, MySQL может быть настроена неверно и неоптимально для текущего железа. В MySQL есть возможность логирования медленных запросов, с помощью которых можно понять, что создаёт реальные проблемы. Как правило, количество select запросов превышает количество запросов на изменение БД. В такой ситуации можно воспользоваться встроенными в MySQL методиками кеширования. Но можно воспользоваться более гибкими внешними решениями, например, Memcache или Redis. При этом кеширование надо использовать как промежуточный этап решения проблемы, при этом по возможности избавляясь от медленных запросов.
Наиболее оптимальным принципом масштабирования БД под высокие нагрузки является шардинг. 
- Если узким местом является бекэнд сервер, то его также можно масштабировать вертикально или горизонтально. При этом, nginx обладает инструментом балансировки нагрузки на бекэнд сервера. Есть 3 метода балансировки:
	1) Round Robin - nginx по умолчанию распределяет запросы равномерно между бекэндами, учитывая веса. 
	2) least_conn - приоритет на получение запросов имеют сервера с наименьшим количеством активных подключений, с учётом веса.
	3) Hash/IP Hash - для каждого запроса nginx вычисляет хэш, который состоит из текста, переменных веб-сервера или их комбинации, а затем сопоставляет его с бекэндами. Таким образом, нгинкс создаёт своего рода постоянные соединения между определённым клиентом и определённым бекэндом. IP Hash работает также, только хэш вычисляет по IP-адресу клиента.
- Фронтенд как правило выдерживает бОльшие нагрузкие, чем прочие компоненты, но его тоже можно оптимизировать. Для этого используется DNS балансировка, а так же Geo DNS. DNS балансировка производится методом Round Robin. В таком случае клиент будет каждый раз получать адрес домена фронтэнд сервера, равномерно распределяясь между всеми имеющимися. Geo DNS позволяет соединять пользователей с фронтэндами, учитывая их местоположение. Персональные данные пользователя можно сохранять в виде кукис.
 
5) В: Какие способы организации доступности сервиса можно применить в случае форс мажорных ситуаций, выхода из строя любого компонента архитектуры?
О: Отказоустойчивость
Если упал один из серверов, нужно перенаправлять/распределять нагрузку на остальные доступные;
Две стратегии: Failover и Fault-tolerance.
Failover. Выход из строя железа решается посредством избыточности, т.е. когда каждый узел имеет резервную копию, которая возьмёт на себя работу основного при выходе его из строя;
Главный принцип - SPOF (Single Point of Failure) - избегать пребывания какого-либо элемента в единственном числе, все компоненты должны быть зарезервированы. 
	- DNS: для одного домена указывается несколько NS записей, чтобы в случае выхода из строя одного из NS сервера запросы обрабатывались другими;
	- Фронтенды: виртуальные IP адреса UCARP. Можно каждую секунду опрашивать корректность работы основного фронта, если корректный ответ не получен - переназначать IP адрес на резервный фронтенд;
	- Бекенды: т.к. они обычно абсолютно идентично, то выход из строя одного сервера просто увеличивает нагрузку на все остальные, нет необходимости в резервации всех бекенд-серверов. Однако нужно правильно рассчитывать исходя из того, что в любой момент может выйти из строя 25% серверов;
	БД: репликация Master-Slave. При выходе мастера из строя, слейв становится мастером. После починки бывшего мастера, он снова реплицируется с бывшим слейвом (ныне мастером) и обратно становится мастер, а слейв обратно становится слейвом.
Fault-tolerance - система отказоустойчивости, при которой компоненты обладают автоматизированной самодиагностикой.
